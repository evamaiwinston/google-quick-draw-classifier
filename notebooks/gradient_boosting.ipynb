{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de93bacb",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47f921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920b3ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (455006, 785), Labels shape: (455006,)\n"
     ]
    }
   ],
   "source": [
    "data = pl.read_parquet('../data/training_data.parquet')\n",
    "\n",
    "X = data.drop(\"label\").select([\n",
    "    pl.col(col).cast(pl.Float32) for col in data.columns if col != \"label\"\n",
    "]).to_numpy()\n",
    "\n",
    "y = data[\"label\"].to_numpy()\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Features shape: {X.shape}, Labels shape: {y_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "# histogram \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "steps = [\n",
    "    ('hgb', HistGradientBoostingClassifier(max_iter = 100, random_state = 42))\n",
    "]\n",
    "\n",
    "gb_pipeline = Pipeline(steps)\n",
    "\n",
    "inner_cv = KFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "\n",
    "param_grid = {\n",
    "    'hgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'hgb__max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    estimator = gb_pipeline,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    cv = inner_cv,\n",
    "    n_jobs = 6,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "gb_start = time.time()\n",
    "gb_grid.fit(X, y_encoded)\n",
    "gb_end = time.time()\n",
    "gb_diff = gb_end - gb_start\n",
    "print(\"Gradient Boosting Training Complete\")\n",
    "print(f\"Time to train Gradient Boosting Model: {np.round(gb_diff, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45711470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (54600, 785), Test shape: (400406, 785)\n",
      "Single Model Fit Complete\n",
      "Time to train: 27.8 seconds\n",
      "Test accuracy: 0.9204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 10% train, 90% test (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    train_size=0.12,\n",
    "    test_size=0.88,\n",
    "    stratify=y_encoded,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Train model\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Single Model Fit Complete\")\n",
    "print(f\"Time to train: {np.round(end - start, 2)} seconds\")\n",
    "\n",
    "# Evaluate on test\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52cfe979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Model Fit Complete\n",
      "Time to train: 11.64 seconds\n",
      "Test accuracy: 0.9430\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Single Model Fit Complete\")\n",
    "print(f\"Time to train: {np.round(end - start, 2)} seconds\")\n",
    "\n",
    "# Evaluate on test\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36260f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = gb_grid.predict(X)  # Use cross-validation predictions if possible\n",
    "print(\"Accuracy:\", accuracy_score(y_encoded, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_encoded, y_pred))\n",
    "print(classification_report(y_encoded, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
