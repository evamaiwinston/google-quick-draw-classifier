{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de93bacb",
   "metadata": {},
   "source": [
    "# Histogram Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47f921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e06a29",
   "metadata": {},
   "source": [
    "## Loading in Data\n",
    "\n",
    "The following code chunk uses polars to load in the training dataset. It then splits the data into X (features) and y (labels) numpy arrays. LabelEncoder is then used to convert the string labels into integers for model training. The shape of the resulting arrays is printed, along with the classes and their corresponding integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920b3ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (68250, 785), Labels shape: (68250,)\n",
      "\n",
      "Classes:\n",
      "0 -> airplane\n",
      "1 -> ice cream\n",
      "2 -> spreadsheet\n",
      "3 -> sword\n"
     ]
    }
   ],
   "source": [
    "# Loading in training data\n",
    "data = pl.read_parquet('../data/training_data.parquet')\n",
    "\n",
    "# Splitting features and labels\n",
    "X = data.drop(\"label\").to_numpy()\n",
    "y = data[\"label\"].to_numpy()\n",
    "\n",
    "# Encoding labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Displaying shapes and encoder mapping\n",
    "print(f\"Features shape: {X.shape}, Labels shape: {y_encoded.shape}\\n\")\n",
    "print(\"Classes:\")\n",
    "for i, class_label in enumerate(encoder.classes_):\n",
    "    print(f\"{i} -> {class_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58693d6c",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The following code chunk uses the HistGradientBoostingClassifier class from sklearn to train a histogram-based gradient boosting model on the training data. Sklearn's Pipeline is used to create a pipeline that includes the classifier, along with KFold and GridSearchCV for cross-validation and hyperparameter tuning. The model is trained on the training data, and the time taken for training is printed.\n",
    "\n",
    "\n",
    "**Note: No preprocessing needed inside pipeline. Feature scaling was performed globally on the dataset before being loaded. All image pixel values were normalized from the range `[0, 255]` to `[0, 1]` by dividing by `255`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bfd83db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Gradient Boosting Training Complete\n",
      "Time to train Gradient Boosting Model: 856.61 seconds | 14.28 minutes\n"
     ]
    }
   ],
   "source": [
    "# Histogram-Based Gradient Boosting Classifier Pipeline\n",
    "\n",
    "# Steps for the pipeline\n",
    "steps = [\n",
    "    ('hgb', HistGradientBoostingClassifier(max_iter = 100, random_state = 42))\n",
    "]\n",
    "\n",
    "# Creating the pipeline\n",
    "hgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Defining inner cross-validation object\n",
    "inner_cv = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "\n",
    "# Defining parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'hgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'hgb__max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Setting up GridSearchCV for Histogram-Based Gradient Boosting Classifier\n",
    "hgb_grid = GridSearchCV(\n",
    "    estimator = hgb_pipeline,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    cv = inner_cv,\n",
    "    n_jobs = 6,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Fitting the model and timing the time to fit\n",
    "hgb_start = time.time()\n",
    "hgb_grid.fit(X, y_encoded)\n",
    "hgb_end = time.time()\n",
    "hgb_diff = hgb_end - hgb_start\n",
    "\n",
    "# Printing at completion of training\n",
    "print(\"Gradient Boosting Training Complete\")\n",
    "print(f\"Time to train Gradient Boosting Model: {np.round(hgb_diff, 2)} seconds | {np.round(hgb_diff / 60, 2)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916a05c",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "The following code chunks retrieve the best hyperparameters found from the grid search and the cross-validation accuracy of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932e808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'hgb__learning_rate': 0.1, 'hgb__max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and print the best model hyperparameters\n",
    "best_params = hgb_grid.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d076509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validation Accuracy: 0.9544\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the cross-validation accuracy\n",
    "cv_accuracy = hgb_grid.best_score_\n",
    "print(f\"Best Cross-Validation Accuracy: {cv_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
