{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254822ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a851b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_df = pd.read_parquet(\"../data/training_data.parquet\")\n",
    "\n",
    "# map labels to ints\n",
    "classes = sorted(train_df[\"label\"].unique())\n",
    "label2idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "train_df[\"y\"] = train_df[\"label\"].map(label2idx)\n",
    "\n",
    "X = train_df.filter(like=\"pixel_\").to_numpy().astype(np.float32)\n",
    "y = train_df[\"y\"].to_numpy().astype(np.int64)\n",
    "# Arrays to tensors\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9493e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, h1, h2, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(784, h1) # 784 input features (28x28 image flattened)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, 4)   # 4 output classes\n",
    "\n",
    "        # Activation and dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x) \n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b3888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def restore_best_weights(self, model):\n",
    "        if self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066c5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hparams(search_space, fixed):\n",
    "    hparams = {}\n",
    "    for key, values in search_space.items():\n",
    "        hparams[key] = np.random.choice(values)\n",
    "    hparams[\"batch_size\"]=fixed[\"batch_size\"]\n",
    "    hparams[\"epochs\"]=fixed[\"epochs\"]\n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa58f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(X_train, y_train, X_val, y_val, hparams):\n",
    "    batch_size = hparams[\"batch_size\"]\n",
    "    droupout = hparams[\"dropout\"]\n",
    "    lr = hparams[\"lr\"]\n",
    "    weight_decay = hparams[\"weight_decay\"]\n",
    "    epochs = hparams[\"epochs\"]\n",
    "\n",
    "    # Datasets and data loaders\n",
    "    train_dataset = TensorDataset(X_train.float(), y_train.long())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val.float(), y_val.long())\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate model\n",
    "    model = MyModel(h1=hparams[\"h1\"], h2=hparams[\"h2\"], dropout=droupout)\n",
    "    # Loss \n",
    "    cost_fn = nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Early Stopping \n",
    "    early_stopping = EarlyStopping(patience=5)\n",
    "    epochs_run = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epochs_run += 1\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = cost_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                logits = model(X_batch)\n",
    "                loss = cost_fn(logits, y_batch)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader) \n",
    "        val_accuracy = correct / total\n",
    "\n",
    "        #--- Early Stopping --- \n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            #print(f\"Stopping early at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # This restores the best model\n",
    "    early_stopping.restore_best_weights(model)\n",
    "    return val_accuracy, epochs_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5a79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search space\n",
    "\n",
    "# ORIGINAL RANDOM SEARCH\n",
    "# search_space = {\n",
    "# #     \"lr\" : [1e-4, 3e-4, 1e-3, 3e-3, 1e-2],\n",
    "# #     \"weight_decay\" : [0.0, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "# #     \"dropout\" : [0.0, 0.2, 0.3, 0.4, 0.5],\n",
    "# #     \"h1\" : [64, 128, 256, 512],\n",
    "# #     \"h2\" : [0, 32, 64, 128, 256]\n",
    "# # }\n",
    "\n",
    "\n",
    "# Focused search\n",
    "search_space = {\n",
    "    \"lr\": [1e-4, 3e-4, 1e-3],              \n",
    "    \"weight_decay\": [1e-5, 1e-4, 1e-3],       \n",
    "    \"dropout\": [0.2, 0.3, 0.4],          \n",
    "    \"h1\": [256, 512],                      \n",
    "    \"h2\": [64, 128, 256]                     \n",
    "}\n",
    "\n",
    "# Fixed hyperparameters\n",
    "fixed = {\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845d009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Mean CV Accuracy = 0.9571, Mean epochs until early stop = 23.4, Hyperparams = {'lr': 0.0001, 'weight_decay': 0.0001, 'dropout': 0.2, 'h1': 256, 'h2': 64}\n",
      "Trial 2: Mean CV Accuracy = 0.9572, Mean epochs until early stop = 21.0, Hyperparams = {'lr': 0.0003, 'weight_decay': 0.001, 'dropout': 0.4, 'h1': 512, 'h2': 64}\n",
      "Trial 3: Mean CV Accuracy = 0.9575, Mean epochs until early stop = 16.4, Hyperparams = {'lr': 0.0003, 'weight_decay': 1e-05, 'dropout': 0.4, 'h1': 256, 'h2': 64}\n",
      "Trial 4: Mean CV Accuracy = 0.9573, Mean epochs until early stop = 13.8, Hyperparams = {'lr': 0.0003, 'weight_decay': 1e-05, 'dropout': 0.3, 'h1': 256, 'h2': 128}\n",
      "Trial 5: Mean CV Accuracy = 0.9571, Mean epochs until early stop = 13.2, Hyperparams = {'lr': 0.0003, 'weight_decay': 0.0001, 'dropout': 0.3, 'h1': 256, 'h2': 256}\n",
      "Trial 6: Mean CV Accuracy = 0.9573, Mean epochs until early stop = 20.2, Hyperparams = {'lr': 0.0003, 'weight_decay': 0.001, 'dropout': 0.2, 'h1': 256, 'h2': 128}\n",
      "Trial 7: Mean CV Accuracy = 0.9562, Mean epochs until early stop = 13.2, Hyperparams = {'lr': 0.001, 'weight_decay': 1e-05, 'dropout': 0.4, 'h1': 256, 'h2': 64}\n",
      "Trial 8: Mean CV Accuracy = 0.9577, Mean epochs until early stop = 15.2, Hyperparams = {'lr': 0.0001, 'weight_decay': 1e-05, 'dropout': 0.2, 'h1': 512, 'h2': 256}\n",
      "Trial 9: Mean CV Accuracy = 0.9568, Mean epochs until early stop = 34.8, Hyperparams = {'lr': 0.0001, 'weight_decay': 0.001, 'dropout': 0.2, 'h1': 256, 'h2': 64}\n",
      "Trial 10: Mean CV Accuracy = 0.9570, Mean epochs until early stop = 36.0, Hyperparams = {'lr': 0.0001, 'weight_decay': 0.001, 'dropout': 0.4, 'h1': 256, 'h2': 64}\n",
      "Trial 11: Mean CV Accuracy = 0.9558, Mean epochs until early stop = 13.2, Hyperparams = {'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'h1': 256, 'h2': 256}\n",
      "Trial 12: Mean CV Accuracy = 0.9589, Mean epochs until early stop = 21.0, Hyperparams = {'lr': 0.0001, 'weight_decay': 1e-05, 'dropout': 0.4, 'h1': 512, 'h2': 128}\n",
      "Trial 13: Mean CV Accuracy = 0.9586, Mean epochs until early stop = 18.0, Hyperparams = {'lr': 0.0001, 'weight_decay': 0.0001, 'dropout': 0.4, 'h1': 512, 'h2': 256}\n",
      "Trial 14: Mean CV Accuracy = 0.9579, Mean epochs until early stop = 25.8, Hyperparams = {'lr': 0.0001, 'weight_decay': 0.0001, 'dropout': 0.4, 'h1': 256, 'h2': 128}\n",
      "Trial 15: Mean CV Accuracy = 0.9555, Mean epochs until early stop = 9.4, Hyperparams = {'lr': 0.001, 'weight_decay': 1e-05, 'dropout': 0.2, 'h1': 512, 'h2': 64}\n",
      "\n",
      "Best config:\n",
      "{'lr': np.float64(0.0001), 'weight_decay': np.float64(1e-05), 'dropout': np.float64(0.4), 'h1': np.int64(512), 'h2': np.int64(128), 'batch_size': 64, 'epochs': 50}\n",
      "Best mean CV Accuracy: 0.9589\n",
      "Average epochs until early stop = 21.0\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "n_trials = 15\n",
    "results = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    hparams = sample_hparams(search_space, fixed)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    fold_epochs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X,y), 1):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        accuracy, epochs_run = train_fold(X_train, y_train, X_val, y_val, hparams)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_epochs.append(epochs_run)\n",
    "        #print(f\"Fold {fold}: Validation Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    mean_accuracy = float(np.mean(fold_accuracies))\n",
    "    mean_epochs = float(np.mean(fold_epochs))\n",
    "\n",
    "    display_hparams = {\n",
    "        k: (float(v) if isinstance(v, np.floating) else int(v) if isinstance(v, np.integer) else v)\n",
    "        for k, v in hparams.items()\n",
    "        if k not in [\"batch_size\", \"epochs\"]\n",
    "    }\n",
    "\n",
    "    results.append({\n",
    "        \"hparams\": hparams,\n",
    "        \"mean_accuracy\": mean_accuracy,\n",
    "        \"mean_epochs\": mean_epochs,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"Trial {trial+1}: Mean CV Accuracy = {mean_accuracy:.4f}, \"\n",
    "        f\"Mean epochs until early stop = {mean_epochs:.1f}, \"\n",
    "        f\"Hyperparams = {display_hparams}\"\n",
    "    )\n",
    "    #print(f\"Trial {trial+1}: Mean CV Accuracy: {mean_accuracy:.4f},\\n Hyperparameters: {hparams}\\n\\n\")\n",
    "    \n",
    "best = max(results, key=lambda x: x[\"mean_accuracy\"])\n",
    "print(\"\\nBest config:\")\n",
    "disp_best = {\n",
    "    k: (float(v) if isinstance(v, np.floating) else int(v) if isinstance(v, np.integer) else v)\n",
    "    for k, v in best[\"hparams\"].items()\n",
    "    if k not in [\"batch_size\", \"epochs\"]\n",
    "}\n",
    "print(best[\"hparams\"])\n",
    "print(f\"Best mean CV Accuracy: {best['mean_accuracy']:.4f}\")\n",
    "print(f\"Average epochs until early stop = {best['mean_epochs']:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4021env (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
